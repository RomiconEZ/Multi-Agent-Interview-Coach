# security-tests-llamator

Набор сценариев для тестирования безопасности LLM/RAG-систем с помощью фреймворка **LLAMATOR**. Проект оформлен как Jupyter Notebook, который настраивает клиентов, выбирает пресеты атак, запускает тестирование и сохраняет артефакты отчетности.

## Состав

- `.env.example` — пример переменных окружения для подключения к OpenAI-совместимому API.
- `llamator.ipynb` — пайплайн тестирования: инициализация клиентов, выбор тестов, запуск атак, генерация отчетов.

## Требования

- Python 3.10+
- Jupyter (Notebook / Lab)
- Доступ к OpenAI-совместимому API (локальный или облачный)

## Установка зависимостей

В ноутбуке используется установка через `pip`:

```bash
pip install -U llamator python-dotenv requests
```

Проверка установленной версии:
```bash
pip show llamator
```

## Настройка окружения

1. Создать `.env` на основе примера:
   ```bash
   cp .env.example .env
   ```

2. Заполнить значения в `.env`:

- `OPENAI_API_KEY` — API ключ.
- `OPENAI_BASEURL` — базовый URL OpenAI-совместимого API.
- `OPENAI_MODEL` — идентификатор модели.

## Пайплайн в ноутбуке

`llamator.ipynb` содержит последовательность шагов.

### 1) Инициализация окружения

- Загрузка переменных окружения из `.env` через `python-dotenv`.
- Импорт зависимостей (`llamator`, `requests`, `pandas`).

### 2) Клиент для REST API (опционально)

Определен класс `ClientAPI`, наследующий `llamator.ClientBase`, для интеграции с тестируемой системой через HTTP POST:

- URL по умолчанию: `http://localhost:8080/api/`
- Контракт запроса: `{"question": "<текст>"}`
- Контракт ответа: `{"answer": "<текст>"}`

### 3) Модели-участники тестирования

В ноутбуке инициализируются три клиента `llamator.ClientOpenAI`:

- `attack_model` — атакующая модель (генерация атакующих промптов).
- `judge_model` — модель-судья (LLM-as-a-Judge, оценка успешности атак).
- `tested_client` — тестируемая модель/система (цель атак).

Параметры подключения берутся из `.env`: `OPENAI_API_KEY`, `OPENAI_BASEURL`, `OPENAI_MODEL`.

### 4) Просмотр пресетов атак

Для ознакомления с доступными наборами атак используется:
```python
llamator.print_test_preset("all")
```

В ноутбуке упомянуты пресеты:
- `all`, `eng`, `rus`
- `owasp:llm01`, `owasp:llm07`, `owasp:llm09`, `owasp:llm10`
- `llm`, `vlm`

### 5) Конфигурация запуска и выбор тестов

Формируется набор тестов `basic_tests` (в ноутбуке — `basic_tests_params`) как список кортежей:
- имя атаки
- параметры атаки (например `num_attempts`, `multistage_depth`, `strategy_library_size`, `custom_dataset`)

Также задается `config` для LLAMATOR:

- `enable_logging` — включение логирования.
- `enable_reports` — включение генерации отчетов.
- `artifacts_path` — каталог для сохранения артефактов.
- `debug_level` — уровень логирования (`0` WARNING, `1` INFO, `2` DEBUG).
- `report_language` — язык отчетов (`en` / `ru`).

### 6) Запуск тестирования

Запуск выполняется через `llamator.start_testing(...)`:

- `attack_model`
- `judge_model`
- `tested_model`
- `config`
- `basic_tests`

Функция возвращает словарь результатов по тестам с метриками:
- `broken`
- `resilient`
- `errors`

## Артефакты и отчеты

При включенном `enable_reports` LLAMATOR сохраняет результаты в каталоге вида:
- `./artifacts/LLAMATOR_run_<YYYY-MM-DD>_<HH-MM-SS>/`

Форматы отчетов:
- Excel (`.xlsx`)
- Word (`.docx`)

## Как использовать

1. Установить зависимости.
2. Подготовить `.env`.
3. Открыть `llamator.ipynb`.
4. Запустить ячейки последовательно:
   - инициализация окружения и клиентов
   - выбор пресетов/тестов
   - запуск тестирования
   - просмотр результатов и сформированных отчетов

## Структура репозитория

- `.env.example`
- `llamator.ipynb`
- `artifacts/` (создается при запуске, содержит отчеты и результаты)
