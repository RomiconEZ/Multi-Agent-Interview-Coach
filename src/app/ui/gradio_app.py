"""
Gradio –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è Multi-Agent Interview Coach.

–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
–¥–ª—è –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω—Ç–µ—Ä–≤—å—é —Å AI-–∞–≥–µ–Ω—Ç–∞–º–∏.
"""

from __future__ import annotations

import asyncio
import logging
from pathlib import Path
from typing import Any

import gradio as gr

from .styles import HEADER_HTML, MAIN_CSS
from ..core.config import settings
from ..core.logger_setup import get_system_logger, setup_logging
from ..interview import InterviewSession, create_interview_session
from ..llm.models import get_models_for_ui
from ..schemas.agent_settings import (
    AgentSettings,
    InterviewConfig,
    SingleAgentConfig,
)

logger: logging.LoggerAdapter[logging.Logger] = get_system_logger(__name__)

_current_session: InterviewSession | None = None
_last_log_path: Path | None = None
_last_detailed_log_path: Path | None = None

# –¢–∏–ø –∫–æ—Ä—Ç–µ–∂–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º–æ–≥–æ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞–º–∏, –æ–±–Ω–æ–≤–ª—è—é—â–∏–º–∏ –≤—Å–µ –≤—ã—Ö–æ–¥—ã.
_FullHandlerResult = tuple[str, str, list[dict[str, str | None]], str, str | None, str | None]

# –¢–∏–ø –∫–æ—Ä—Ç–µ–∂–∞ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ —à–∞–≥–∞ 1 (—Ç–æ–ª—å–∫–æ msg_input + chatbot).
_UserStepResult = tuple[str, list[dict[str, str | None]]]

# –¢–∏–ø –∫–æ—Ä—Ç–µ–∂–∞ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ —à–∞–≥–∞ 2 (–≤—Å—ë, –∫—Ä–æ–º–µ msg_input).
_BotStepResult = tuple[str, list[dict[str, str | None]], str, str | None, str | None]


def _run_async(coro: Any) -> Any:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –∫–æ—Ä—É—Ç–∏–Ω—É –≤ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ Gradio.

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤, –∫–æ—Ç–æ—Ä—ã–º —Ç—Ä–µ–±—É–µ—Ç—Å—è —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤
    (–Ω–∞–ø—Ä–∏–º–µ—Ä, ``start_interview``, ``stop_interview``, ``reset_interview``).
    –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –≤ –≥–æ—Ä—è—á–µ–º –ø—É—Ç–∏ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –æ–±—ä—è–≤–ª–µ–Ω—ã –∫–∞–∫ ``async def``
    –Ω–∞–ø—Ä—è–º—É—é, —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å event loop Gradio.

    :param coro: –ö–æ—Ä—É—Ç–∏–Ω–∞ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è.
    :return: –†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ—Ä—É—Ç–∏–Ω—ã.
    """
    try:
        loop = asyncio.get_event_loop()
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

    if loop.is_running():
        import nest_asyncio

        nest_asyncio.apply()

    return loop.run_until_complete(coro)


def _build_interview_config(
        model: str,
        max_turns: int,
        job_description: str,
        obs_temp: float,
        obs_tokens: int,
        int_temp: float,
        int_tokens: int,
        eval_temp: float,
        eval_tokens: int,
) -> InterviewConfig:
    """
    –°–æ–±–∏—Ä–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–Ω—Ç–µ—Ä–≤—å—é –∏–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ UI.

    :param model: –ò–º—è –º–æ–¥–µ–ª–∏ LLM.
    :param max_turns: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ö–æ–¥–æ–≤.
    :param job_description: –û–ø–∏—Å–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏.
    :param obs_temp: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ Observer.
    :param obs_tokens: –ú–∞–∫—Å. —Ç–æ–∫–µ–Ω–æ–≤ Observer.
    :param int_temp: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ Interviewer.
    :param int_tokens: –ú–∞–∫—Å. —Ç–æ–∫–µ–Ω–æ–≤ Interviewer.
    :param eval_temp: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ Evaluator.
    :param eval_tokens: –ú–∞–∫—Å. —Ç–æ–∫–µ–Ω–æ–≤ Evaluator.
    :return: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–Ω—Ç–µ—Ä–≤—å—é.
    """
    return InterviewConfig(
        model=model.strip() if model and model.strip() else None,
        max_turns=max_turns,
        job_description=job_description.strip()
        if job_description and job_description.strip()
        else None,
        agent_settings=AgentSettings(
            observer=SingleAgentConfig(
                temperature=obs_temp, max_tokens=obs_tokens, generation_retries=2,
            ),
            interviewer=SingleAgentConfig(
                temperature=int_temp, max_tokens=int_tokens, generation_retries=0,
            ),
            evaluator=SingleAgentConfig(
                temperature=eval_temp, max_tokens=eval_tokens, generation_retries=2,
            ),
        ),
    )


async def _start_interview_async(
        model: str,
        max_turns: int,
        job_description: str,
        obs_temp: float,
        obs_tokens: int,
        int_temp: float,
        int_tokens: int,
        eval_temp: float,
        eval_tokens: int,
) -> _FullHandlerResult:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –Ω–∞—á–∏–Ω–∞–µ—Ç –Ω–æ–≤–æ–µ –∏–Ω—Ç–µ—Ä–≤—å—é.

    :return: Tuple (—Å—Ç–∞—Ç—É—Å, –æ—á–∏—â–µ–Ω–Ω—ã–π –∏–Ω–ø—É—Ç, –∏—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞, —Ñ–∏–¥–±—ç–∫, –ª–æ–≥, –¥–µ—Ç–∞–ª—å–Ω—ã–π –ª–æ–≥).
    """
    global _current_session, _last_log_path, _last_detailed_log_path

    if _current_session is not None:
        await _current_session.close()

    _last_log_path = None
    _last_detailed_log_path = None

    config: InterviewConfig = _build_interview_config(
        model,
        max_turns,
        job_description,
        obs_temp,
        obs_tokens,
        int_temp,
        int_tokens,
        eval_temp,
        eval_tokens,
    )

    try:
        _current_session = await create_interview_session(config)
        greeting: str = await _current_session.start()
    except Exception as e:
        logger.error(f"Failed to start interview: {type(e).__name__}: {e}")
        _current_session = None
        return (
            f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∏–Ω—Ç–µ—Ä–≤—å—é: {e}",
            "",
            [],
            "",
            None,
            None,
        )

    actual_model: str = _current_session._llm_client.model
    jd_indicator: str = " | üìã –í–∞–∫–∞–Ω—Å–∏—è –∑–∞–¥–∞–Ω–∞" if config.job_description else ""
    status: str = f"‚úÖ –ò–Ω—Ç–µ—Ä–≤—å—é –Ω–∞—á–∞—Ç–æ | –ú–æ–¥–µ–ª—å: {actual_model}{jd_indicator}"
    history: list[dict[str, str | None]] = [{"role": "assistant", "content": greeting}]

    return status, "", history, "", None, None


def start_interview(
        model: str,
        max_turns: int,
        job_description: str,
        obs_temp: float,
        obs_tokens: int,
        int_temp: float,
        int_tokens: int,
        eval_temp: float,
        eval_tokens: int,
) -> _FullHandlerResult:
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—ë—Ä—Ç–∫–∞ –¥–ª—è —Å—Ç–∞—Ä—Ç–∞ –∏–Ω—Ç–µ—Ä–≤—å—é."""
    return _run_async(
        _start_interview_async(
            model,
            max_turns,
            job_description,
            obs_temp,
            obs_tokens,
            int_temp,
            int_tokens,
            eval_temp,
            eval_tokens,
        )
    )


def add_user_message(
        message: str,
        history: list[dict[str, str | None]],
) -> _UserStepResult:
    """
    –ú–≥–Ω–æ–≤–µ–Ω–Ω–æ –¥–æ–±–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ –∏ –æ—á–∏—â–∞–µ—Ç –ø–æ–ª–µ –≤–≤–æ–¥–∞.

    –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —Å ``queue=False`` ‚Äî –æ–±—Ö–æ–¥–∏—Ç –æ—á–µ—Ä–µ–¥—å Gradio –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç UI
    –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ, –Ω–µ –¥–æ–∂–∏–¥–∞—è—Å—å –æ—Ç–≤–µ—Ç–∞ –æ—Ç LLM. –Ø–≤–ª—è–µ—Ç—Å—è —á–∏—Å—Ç–æ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–µ–π:
    –Ω–µ –≤—ã–∑—ã–≤–∞–µ—Ç LLM –∏ –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç event loop.

    :param message: –¢–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –∫–∞–Ω–¥–∏–¥–∞—Ç–∞.
    :param history: –¢–µ–∫—É—â–∞—è –∏—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞.
    :return: Tuple (–æ—á–∏—â–µ–Ω–Ω—ã–π –∏–Ω–ø—É—Ç, –æ–±–Ω–æ–≤–ª—ë–Ω–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è —Å —Å–æ–æ–±—â–µ–Ω–∏–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è).
    """
    if not message.strip():
        return message, history

    updated_history: list[dict[str, str | None]] = list(history)
    updated_history.append({"role": "user", "content": message})
    return "", updated_history


async def bot_respond(
        history: list[dict[str, str | None]],
) -> _BotStepResult:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–≤–µ—Ç –∞–≥–µ–Ω—Ç–∞.

    –û–±—ä—è–≤–ª–µ–Ω–∞ –∫–∞–∫ ``async def`` ‚Äî Gradio –≤—ã–∑—ã–≤–∞–µ—Ç –µ—ë —á–µ—Ä–µ–∑ ``await``,
    —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç event loop –æ—Å—Ç–∞–≤–∞—Ç—å—Å—è –Ω–µ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∏ –¥–æ—Å—Ç–∞–≤–∏—Ç—å
    –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ—Ç —à–∞–≥–∞ 1 (—Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è) –≤ –±—Ä–∞—É–∑–µ—Ä –¥–æ –Ω–∞—á–∞–ª–∞ LLM-–≤—ã–∑–æ–≤–∞.

    –í—ã–∑—ã–≤–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ ``.then()`` –ø–æ—Å–ª–µ :func:`add_user_message`.

    :param history: –ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞ —Å —É–∂–µ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
    :return: Tuple (—Å—Ç–∞—Ç—É—Å, –æ–±–Ω–æ–≤–ª—ë–Ω–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è —Å –æ—Ç–≤–µ—Ç–æ–º –∞–≥–µ–Ω—Ç–∞, —Ñ–∏–¥–±—ç–∫, –ª–æ–≥, –¥–µ—Ç–∞–ª—å–Ω—ã–π –ª–æ–≥).
    """
    global _current_session, _last_log_path, _last_detailed_log_path

    if _current_session is None:
        return "‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ –Ω–∞—á–Ω–∏—Ç–µ –∏–Ω—Ç–µ—Ä–≤—å—é", history, "", None, None

    user_message: str = ""
    for msg in reversed(history):
        if msg.get("role") == "user":
            user_message = str(msg.get("content") or "")
            break

    if not user_message.strip():
        return "‚ö†Ô∏è –°–æ–æ–±—â–µ–Ω–∏–µ –ø—É—Å—Ç–æ–µ", history, "", None, None

    response: str
    is_finished: bool

    try:
        response, is_finished = await _current_session.process_message(user_message.strip())
    except Exception as e:
        logger.error(f"Unexpected error in process_message: {type(e).__name__}: {e}")
        return (
            f"‚ùå –û—à–∏–±–∫–∞: {e}",
            history,
            "",
            None,
            None,
        )

    updated_history: list[dict[str, str | None]] = list(history)
    updated_history.append({"role": "assistant", "content": response})

    if is_finished:
        try:
            feedback, summary_path, detailed_path = await _current_session.generate_feedback()
        except Exception as e:
            logger.error(f"Feedback generation failed: {type(e).__name__}: {e}")
            return (
                f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ñ–∏–¥–±—ç–∫–∞: {e}",
                updated_history,
                "",
                None,
                None,
            )

        feedback_text: str = feedback.to_formatted_string()

        metrics = _current_session.get_session_metrics()
        if metrics:
            feedback_text += "\n\n" + metrics.to_summary_string()

        _last_log_path = summary_path
        _last_detailed_log_path = detailed_path

        return (
            "‚úÖ –ò–Ω—Ç–µ—Ä–≤—å—é –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –§–∏–¥–±—ç–∫ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω.",
            updated_history,
            feedback_text,
            str(summary_path),
            str(detailed_path),
        )

    current_turn: str = str(
        _current_session.state.current_turn if _current_session.state else "?"
    )
    max_turns_val: str = str(_current_session._config.max_turns)
    status = f"üí¨ –•–æ–¥ {current_turn}/{max_turns_val}"

    return status, updated_history, "", None, None


async def stop_interview(
        history: list[dict[str, str | None]],
) -> tuple[str, list[dict[str, str | None]], str, str | None, str | None]:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –∑–∞–≤–µ—Ä—à–∞–µ—Ç –∏–Ω—Ç–µ—Ä–≤—å—é –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ñ–∏–¥–±—ç–∫.

    :param history: –ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞.
    :return: Tuple (—Å—Ç–∞—Ç—É—Å, –∏—Å—Ç–æ—Ä–∏—è, —Ñ–∏–¥–±—ç–∫, –ª–æ–≥, –¥–µ—Ç–∞–ª—å–Ω—ã–π –ª–æ–≥).
    """
    global _current_session, _last_log_path, _last_detailed_log_path

    if _current_session is None:
        return "‚ö†Ô∏è –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤—å—é", history, "", None, None

    if _current_session._state:
        _current_session._state.is_active = False

    try:
        feedback, summary_path, detailed_path = await _current_session.generate_feedback()
    except Exception as e:
        logger.error(f"Feedback generation failed on stop: {type(e).__name__}: {e}")
        return (
            f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ñ–∏–¥–±—ç–∫–∞: {e}",
            history,
            "",
            None,
            None,
        )

    feedback_text: str = feedback.to_formatted_string()

    metrics = _current_session.get_session_metrics()
    if metrics:
        feedback_text += "\n\n" + metrics.to_summary_string()

    _last_log_path = summary_path
    _last_detailed_log_path = detailed_path

    updated_history: list[dict[str, str | None]] = list(history)
    updated_history.append({"role": "user", "content": "–°—Ç–æ–ø –∏–Ω—Ç–µ—Ä–≤—å—é"})
    updated_history.append(
        {"role": "assistant", "content": "–ò–Ω—Ç–µ—Ä–≤—å—é –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –§–æ—Ä–º–∏—Ä—É—é —Ñ–∏–¥–±—ç–∫..."}
    )

    return (
        "‚úÖ –ò–Ω—Ç–µ—Ä–≤—å—é –∑–∞–≤–µ—Ä—à–µ–Ω–æ",
        updated_history,
        feedback_text,
        str(summary_path),
        str(detailed_path),
    )


async def reset_interview() -> _FullHandlerResult:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —Å–±—Ä–∞—Å—ã–≤–∞–µ—Ç —Ç–µ–∫—É—â–µ–µ –∏–Ω—Ç–µ—Ä–≤—å—é.

    –ó–∞–∫—Ä—ã–≤–∞–µ—Ç –∞–∫—Ç–∏–≤–Ω—É—é —Å–µ—Å—Å–∏—é –∏ –æ—á–∏—â–∞–µ—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
    –¥–ª—è –Ω–∞—á–∞–ª–∞ –Ω–æ–≤–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤—å—é.

    :return: Tuple (—Å—Ç–∞—Ç—É—Å, –æ—á–∏—â–µ–Ω–Ω—ã–π –∏–Ω–ø—É—Ç, –ø—É—Å—Ç–∞—è –∏—Å—Ç–æ—Ä–∏—è, –ø—É—Å—Ç–æ–π —Ñ–∏–¥–±—ç–∫, None, None).
    """
    global _current_session, _last_log_path, _last_detailed_log_path

    if _current_session is not None:
        await _current_session.close()
        _current_session = None

    _last_log_path = None
    _last_detailed_log_path = None

    return (
        "üîÑ –°–µ—Å—Å–∏—è —Å–±—Ä–æ—à–µ–Ω–∞. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –Ω–∞—á–Ω–∏—Ç–µ –Ω–æ–≤–æ–µ –∏–Ω—Ç–µ—Ä–≤—å—é.",
        "",
        [],
        "",
        None,
        None,
    )


def refresh_models() -> gr.update:
    """
    –û–±–Ω–æ–≤–ª—è–µ—Ç —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –∏–∑ LiteLLM API.

    :return: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ Dropdown —Å–æ —Å–ø–∏—Å–∫–æ–º –º–æ–¥–µ–ª–µ–π.
    """
    models: list[str] = get_models_for_ui()
    default_value: str = settings.LITELLM_MODEL
    value: str = (
        default_value if default_value in models else (models[0] if models else "")
    )
    return gr.update(choices=models, value=value)


def create_gradio_interface() -> gr.Blocks:
    """
    –°–æ–∑–¥–∞—ë—Ç Gradio –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.

    :return: –û–±—ä–µ–∫—Ç Gradio Blocks —Å –ø–æ–ª–Ω–æ—Å—Ç—å—é –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º.
    """
    initial_models: list[str] = get_models_for_ui()
    default_model: str = settings.LITELLM_MODEL
    initial_model_value: str = (
        default_model
        if default_model in initial_models
        else (initial_models[0] if initial_models else "")
    )

    with gr.Blocks(
            title="Multi-Agent Interview Coach",
            theme=gr.themes.Base(
                primary_hue=gr.themes.colors.indigo,
                secondary_hue=gr.themes.colors.purple,
                neutral_hue=gr.themes.colors.slate,
                font=[gr.themes.GoogleFont("Inter"), "system-ui", "sans-serif"],
                font_mono=[gr.themes.GoogleFont("JetBrains Mono"), "Consolas", "monospace"],
            ).set(
                body_background_fill="#0f1117",
                body_background_fill_dark="#0f1117",
                block_background_fill="transparent",
                block_background_fill_dark="transparent",
                block_border_color="rgba(99, 102, 241, 0.15)",
                block_border_color_dark="rgba(99, 102, 241, 0.15)",
                block_label_background_fill="transparent",
                block_label_background_fill_dark="transparent",
                block_label_text_color="#94a3b8",
                block_label_text_color_dark="#94a3b8",
                block_title_text_color="#e2e8f0",
                block_title_text_color_dark="#e2e8f0",
                input_background_fill="#24253a",
                input_background_fill_dark="#24253a",
                input_border_color="rgba(99, 102, 241, 0.15)",
                input_border_color_dark="rgba(99, 102, 241, 0.15)",
                background_fill_primary="#0f1117",
                background_fill_primary_dark="#0f1117",
                background_fill_secondary="transparent",
                background_fill_secondary_dark="transparent",
                panel_background_fill="transparent",
                panel_background_fill_dark="transparent",
                code_background_fill="#24253a",
                code_background_fill_dark="#24253a",
                checkbox_background_color="#24253a",
                checkbox_background_color_dark="#24253a",
                button_primary_background_fill="#6366f1",
                button_primary_background_fill_dark="#6366f1",
                button_primary_background_fill_hover="#4f46e5",
                button_primary_background_fill_hover_dark="#4f46e5",
                button_primary_text_color="white",
                button_primary_text_color_dark="white",
                button_secondary_background_fill="#2e3048",
                button_secondary_background_fill_dark="#2e3048",
                button_secondary_background_fill_hover="#24253a",
                button_secondary_background_fill_hover_dark="#24253a",
                button_secondary_text_color="#94a3b8",
                button_secondary_text_color_dark="#94a3b8",
                body_text_color="#e2e8f0",
                body_text_color_dark="#e2e8f0",
                body_text_color_subdued="#94a3b8",
                body_text_color_subdued_dark="#94a3b8",
                border_color_primary="rgba(99, 102, 241, 0.15)",
                border_color_primary_dark="rgba(99, 102, 241, 0.15)",
            ),
            css=MAIN_CSS,
    ) as app:
        # ‚îÄ‚îÄ Header ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        gr.HTML(HEADER_HTML)

        # ‚îÄ‚îÄ Main Layout ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        with gr.Row(equal_height=False):
            # ‚îÄ‚îÄ Left Column: Settings ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            with gr.Column(scale=3, min_width=320):
                with gr.Group(elem_classes=["settings-panel"]):
                    gr.HTML('<div class="panel-title">‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–Ω—Ç–µ—Ä–≤—å—é</div>')

                    # Model selection
                    with gr.Accordion("ü§ñ –ú–æ–¥–µ–ª—å LLM", open=True):
                        with gr.Row():
                            model_dropdown = gr.Dropdown(
                                label="–ú–æ–¥–µ–ª—å",
                                choices=initial_models,
                                value=initial_model_value,
                                interactive=True,
                                elem_classes=["model-selector"],
                                scale=5,
                            )
                            refresh_btn = gr.Button(
                                "üîÑ",
                                variant="secondary",
                                scale=1,
                                min_width=42,
                                size="sm",
                                elem_classes=["btn-refresh"],
                            )

                        max_turns_slider = gr.Slider(
                            label="–ú–∞–∫—Å. —Ö–æ–¥–æ–≤ –∏–Ω—Ç–µ—Ä–≤—å—é",
                            minimum=5,
                            maximum=50,
                            value=settings.MAX_TURNS,
                            step=1,
                        )

                    # Job description
                    with gr.Accordion("üìã –û–ø–∏—Å–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏", open=False):
                        job_description_input = gr.Textbox(
                            label="–û–ø–∏—Å–∞–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏",
                            placeholder=(
                                "–û–ø–∏—à–∏—Ç–µ –≤–∞–∫–∞–Ω—Å–∏—é, —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –∫–∞–Ω–¥–∏–¥–∞—Ç—É, "
                                "—Å—Ç–µ–∫ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π, –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏...\n\n"
                                "–ï—Å–ª–∏ –æ—Å—Ç–∞–≤–∏—Ç—å –ø—É—Å—Ç—ã–º ‚Äî –∏–Ω—Ç–µ—Ä–≤—å—é –±—É–¥–µ—Ç –æ–±—â–∏–º."
                            ),
                            lines=6,
                            max_lines=15,
                            elem_classes=["job-desc-input"],
                        )

                    # Agent settings
                    with gr.Accordion("üõ†Ô∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–≥–µ–Ω—Ç–æ–≤", open=False):
                        gr.HTML(
                            '<p class="hint-text">'
                            "–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: 0 ‚Äî —Ç–æ—á–Ω—ã–π, 1+ ‚Äî –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–π. "
                            "–¢–æ–∫–µ–Ω—ã: –º–∞–∫—Å–∏–º—É–º –¥–ª–∏–Ω—ã –æ—Ç–≤–µ—Ç–∞ –∞–≥–µ–Ω—Ç–∞."
                            "</p>"
                        )

                        with gr.Accordion("üëÅÔ∏è Observer", open=False):
                            with gr.Group(elem_classes=["agent-config-section"]):
                                obs_temp = gr.Slider(
                                    label="–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞",
                                    minimum=0.0,
                                    maximum=1.5,
                                    value=0.3,
                                    step=0.05,
                                )
                                obs_tokens = gr.Slider(
                                    label="–ú–∞–∫—Å. —Ç–æ–∫–µ–Ω–æ–≤",
                                    minimum=256,
                                    maximum=4096,
                                    value=1000,
                                    step=64,
                                )

                        with gr.Accordion("üé§ Interviewer", open=False):
                            with gr.Group(elem_classes=["agent-config-section"]):
                                int_temp = gr.Slider(
                                    label="–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞",
                                    minimum=0.0,
                                    maximum=1.5,
                                    value=0.7,
                                    step=0.05,
                                )
                                int_tokens = gr.Slider(
                                    label="–ú–∞–∫—Å. —Ç–æ–∫–µ–Ω–æ–≤",
                                    minimum=256,
                                    maximum=4096,
                                    value=800,
                                    step=64,
                                )

                        with gr.Accordion("üìä Evaluator", open=False):
                            with gr.Group(elem_classes=["agent-config-section"]):
                                eval_temp = gr.Slider(
                                    label="–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞",
                                    minimum=0.0,
                                    maximum=1.5,
                                    value=0.3,
                                    step=0.05,
                                )
                                eval_tokens = gr.Slider(
                                    label="–ú–∞–∫—Å. —Ç–æ–∫–µ–Ω–æ–≤",
                                    minimum=512,
                                    maximum=8192,
                                    value=3000,
                                    step=128,
                                )

                    # Action buttons
                    gr.HTML('<hr class="section-divider">')

                    start_btn = gr.Button(
                        "üöÄ –ù–∞—á–∞—Ç—å –∏–Ω—Ç–µ—Ä–≤—å—é",
                        variant="primary",
                        elem_classes=["btn-start"],
                    )

                    with gr.Row():
                        stop_btn = gr.Button(
                            "üõë –ó–∞–≤–µ—Ä—à–∏—Ç—å",
                            variant="stop",
                            elem_classes=["btn-stop"],
                            scale=1,
                        )
                        reset_btn = gr.Button(
                            "üîÑ –°–±—Ä–æ—Å–∏—Ç—å",
                            variant="secondary",
                            elem_classes=["btn-reset"],
                            scale=1,
                        )

                    status_output = gr.Textbox(
                        label="–°—Ç–∞—Ç—É—Å",
                        value="‚è≥ –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –Ω–∞–∂–º–∏—Ç–µ ¬´–ù–∞—á–∞—Ç—å –∏–Ω—Ç–µ—Ä–≤—å—é¬ª",
                        interactive=False,
                        elem_classes=["status-bar"],
                    )

            # ‚îÄ‚îÄ Right Column: Chat + Feedback ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            with gr.Column(scale=9, min_width=600):
                with gr.Tabs() as tabs:
                    # Tab 1: Interview Chat
                    with gr.TabItem("üí¨ –ò–Ω—Ç–µ—Ä–≤—å—é", id=0):
                        chatbot = gr.Chatbot(
                            label="–î–∏–∞–ª–æ–≥ —Å –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–æ–º",
                            height=560,
                            type="messages",
                            elem_classes=["chat-area"],
                            show_copy_button=True,
                            avatar_images=(None, None),
                            placeholder=(
                                "<center style='background: transparent !important;'>"
                                "<br><br>"
                                "<h3 style='color: #64748b; background: transparent !important;'>"
                                "üéØ –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å!</h3>"
                                "<p style='color: #475569; font-size: 0.9rem; background: transparent !important;'>"
                                "–ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–ª–µ–≤–∞ –∏ –Ω–∞–∂–º–∏—Ç–µ "
                                "<strong>¬´–ù–∞—á–∞—Ç—å –∏–Ω—Ç–µ—Ä–≤—å—é¬ª</strong> –¥–ª—è –Ω–∞—á–∞–ª–∞."
                                "</p>"
                                "</center>"
                            ),
                        )

                        with gr.Row():
                            msg_input = gr.Textbox(
                                label="–í–∞—à –æ—Ç–≤–µ—Ç",
                                placeholder="–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –æ—Ç–≤–µ—Ç –∏ –Ω–∞–∂–º–∏—Ç–µ Enter –∏–ª–∏ –∫–Ω–æ–ø–∫—É ¬´–û—Ç–ø—Ä–∞–≤–∏—Ç—å¬ª...",
                                lines=2,
                                max_lines=6,
                                scale=6,
                                elem_classes=["input-area"],
                            )
                            send_btn = gr.Button(
                                "üì§",
                                scale=1,
                                min_width=60,
                                elem_classes=["btn-send"],
                            )

                    # Tab 2: Feedback
                    with gr.TabItem("üìä –§–∏–¥–±—ç–∫", id=1):
                        with gr.Group(elem_classes=["feedback-panel"]):
                            feedback_output = gr.Textbox(
                                label="–§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞",
                                lines=25,
                                max_lines=50,
                                interactive=False,
                                show_copy_button=True,
                                placeholder="–§–∏–¥–±—ç–∫ –ø–æ—è–≤–∏—Ç—Å—è –∑–¥–µ—Å—å –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∏–Ω—Ç–µ—Ä–≤—å—é...",
                            )

                        with gr.Row(elem_classes=["download-section"]):
                            main_log_file = gr.File(
                                label="üìÑ –û—Å–Ω–æ–≤–Ω–æ–π –ª–æ–≥",
                                interactive=False,
                                scale=1,
                            )
                            detailed_log_file = gr.File(
                                label="üìÑ –î–µ—Ç–∞–ª—å–Ω—ã–π –ª–æ–≥",
                                interactive=False,
                                scale=1,
                            )

        # ‚îÄ‚îÄ Shared inputs for agent settings ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        settings_inputs: list[gr.components.Component] = [
            model_dropdown,
            max_turns_slider,
            job_description_input,
            obs_temp,
            obs_tokens,
            int_temp,
            int_tokens,
            eval_temp,
            eval_tokens,
        ]

        all_outputs: list[gr.components.Component] = [
            status_output,
            msg_input,
            chatbot,
            feedback_output,
            main_log_file,
            detailed_log_file,
        ]

        # –í—ã—Ö–æ–¥—ã –≤—Ç–æ—Ä–æ–≥–æ —à–∞–≥–∞ (–≤—Å—ë –∫—Ä–æ–º–µ msg_input).
        bot_outputs: list[gr.components.Component] = [
            status_output,
            chatbot,
            feedback_output,
            main_log_file,
            detailed_log_file,
        ]

        # ‚îÄ‚îÄ Event Handlers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

        refresh_btn.click(
            fn=refresh_models,
            inputs=[],
            outputs=[model_dropdown],
        )

        start_btn.click(
            fn=start_interview,
            inputs=settings_inputs,
            outputs=all_outputs,
        )

        # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–≤—É—Ö—à–∞–≥–æ–≤–æ–π –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è:
        # –®–∞–≥ 1 (queue=False, sync): –º–≥–Ω–æ–≤–µ–Ω–Ω–æ –¥–æ–±–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        #   –≤ —á–∞—Ç –∏ –æ—á–∏—â–∞–µ—Ç –ø–æ–ª–µ –≤–≤–æ–¥–∞ ‚Äî –±—Ä–∞—É–∑–µ—Ä –ø–æ–ª—É—á–∞–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ.
        # –®–∞–≥ 2 (.then, async def, show_progress="hidden"): Gradio –≤—ã–∑—ã–≤–∞–µ—Ç —á–µ—Ä–µ–∑
        #   await; show_progress="hidden" —É–±–∏—Ä–∞–µ—Ç –æ–≤–µ—Ä–ª–µ–π –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ chatbot,
        #   –∫–æ—Ç–æ—Ä—ã–π –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å–∫—Ä—ã–≤–∞–µ—Ç –≤–µ—Å—å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –≤–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è LLM.
        send_btn.click(
            fn=add_user_message,
            inputs=[msg_input, chatbot],
            outputs=[msg_input, chatbot],
            queue=False,
        ).then(
            fn=bot_respond,
            inputs=[chatbot],
            outputs=bot_outputs,
            show_progress="hidden",
        )

        msg_input.submit(
            fn=add_user_message,
            inputs=[msg_input, chatbot],
            outputs=[msg_input, chatbot],
            queue=False,
        ).then(
            fn=bot_respond,
            inputs=[chatbot],
            outputs=bot_outputs,
            show_progress="hidden",
        )

        stop_btn.click(
            fn=stop_interview,
            inputs=[chatbot],
            outputs=[
                status_output,
                chatbot,
                feedback_output,
                main_log_file,
                detailed_log_file,
            ],
        )

        reset_btn.click(
            fn=reset_interview,
            inputs=[],
            outputs=all_outputs,
        )

    return app


def launch_app(
        server_name: str,
        server_port: int,
        share: bool,
) -> None:
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç Gradio –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ.

    :param server_name: –•–æ—Å—Ç —Å–µ—Ä–≤–µ—Ä–∞.
    :param server_port: –ü–æ—Ä—Ç —Å–µ—Ä–≤–µ—Ä–∞.
    :param share: –°–æ–∑–¥–∞—Ç—å –ø—É–±–ª–∏—á–Ω—É—é —Å—Å—ã–ª–∫—É.
    """
    setup_logging()
    logger.info(f"Launching Gradio app on {server_name}:{server_port}")

    app: gr.Blocks = create_gradio_interface()
    app.launch(server_name=server_name, server_port=server_port, share=share)